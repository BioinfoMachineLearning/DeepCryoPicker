{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":140,"status":"ok","timestamp":1683849992484,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"},"user_tz":300},"id":"t8ofVNhQ1QqB"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import os\n","import cv2\n","import shutil\n","from PIL import Image\n","from skimage import exposure, restoration, color\n","from skimage.morphology import disk, closing\n","from skimage.filters import gaussian\n","from scipy.signal import convolve2d\n","import matplotlib.pyplot as plt\n","import glob\n","import mrcfile\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TImLlYXLb0cn"},"source":["**Setup Directory Paths**\n","\n","Path - location of raw datasets\n","\n","path_output - where preprocessed images will be saved\n","\n","**NOTE**\n","images will be saved as .npy, this is a numpy file type\n","We need to save the files as npy inorder to preserve the normalized values as float32.\n","\n","If you want to save the images as png or jpg, then run the npyToFiletype utility."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683849993486,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"},"user_tz":300},"id":"DFj6orR21ksy"},"outputs":[],"source":["#drive path to directory containg datasets\n","path = \"../Data Sets/Raw Datasets\"\n","\n","#drive path to output directory for preprocessed_data\n","path_output = \"../Data Sets/Processed Datasets\""]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ERD4oPVV7wcF"},"source":["**PreProcessing Function**\n","\n","Preprocessing is a critical step in image analysis that involves preparing the image data for further processing. This typically involves a series of operations to correct for various artifacts and distortions in the image data, and to extract relevant features from the images. \n","\n","\n","The goal of preprocessing is to improve the quality and relevance of the image data, and to prepare it for further processing and analysis. Proper preprocessing can have a significant impact on the accuracy and reliability of downstream analysis, so it is important to carefully choose and optimize preprocessing steps for each particular application. \n","\n","For this model the following are the preprocessing steps taken:\n","\n","\n",">   **Image Normalization**\n",">> Indented scales the pixel values of an image to a consistent range or distribution. This helps to remove biases or inconsistencies in the data and improve its suitability for subsequent processing and analysis.\n","\n","> **Image Adjustment**\n",">> involves modifying the pixel values of an image to improve its quality or contrast. Here we use stretch and gamma adjustment\n","\n","> **Image Restoration**\n",">>  aims to improve the quality of an image by removing noise, blurring, or other distortions.The practices used here are:\n",">>>**Histogram equalization**\n",">>>>enhances the contrast of an image by redistributing the pixel intensities. This involves adjusting the image's histogram so that it is more evenly distributed across the available range of pixel values.\n","\n",">>>**Weiner Deconvolution**\n",">>>> technique used to restore images that have been degraded by blurring or noise. It involves applying a deconvolution filter to the image, which estimates the original, unblurred image by removing the effects of the blurring process. \n","\n",">**Adaptive Histogram Equalization**\n",">>hance the contrast of an image, particularly in areas with low contrast or uneven illumination. Unlike traditional histogram equalization, which operates on the entire image, AHE applies the equalization on local patches of the image. This means that the contrast enhancement is localized to specific regions of the image, preserving the contrast in other regions. \n","\n",">**Gaussian Filtering**\n",">>smoothing an image by applying a Gaussian filter to the image data. The Gaussian filter is a low-pass filter that effectively removes high-frequency noise from the image, while preserving the overall spatial structure of the image.\n","\n",">**Morphological Operations (closing)**\n",">> technique that involves modifying the shape or structure of objects in an image. These operations can be used to remove noise or to enhance specific features in an image, such as edges or boundaries. \n","\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683849993487,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"},"user_tz":300},"id":"xbdsHgCF0aS4"},"outputs":[],"source":["def preprocess_image(image_data):\n","    # preprocessing\n","    # image normalization: pixel values are in the range [0,1]\n","    normalized_data = image_data/np.max(image_data)\n","    # conver image to greyscale\n","    gray_image_data = color.rgb2gray(normalized_data)\n","    # # image adjustment (stretch and adjust)\n","    # # stretch the contrast of the image to represent the 5th and 95th percentiles of the pixel intensity distribution\n","    p1, p2 = np.percentile(gray_image_data, (5,95))\n","    stretched_data = exposure.rescale_intensity(gray_image_data, in_range=(p1, p2))\n","    # Adjust the contrast and brightness of the image\n","    adjusted_data = exposure.adjust_gamma(stretched_data, gamma=0.5)\n","    # image restoration (histogram equalization and weiner deconvolution)\n","    # histogram equalization\n","    histeq_data = exposure.equalize_hist(adjusted_data)\n","    # weiner deconvolution\n","    # the psf used is a general approximation, a better estimate can be created for our data set (possible improvment, though probably small)\n","    psf = np.ones((3, 3)) / 9\n","    blurred_data = convolve2d(histeq_data, psf, mode='same', boundary='symm')\n","    wiener_deconvolved_data = restoration.wiener(blurred_data, psf, balance=0.1)\n","    # histogram equlization\n","    histeq_data = exposure.equalize_hist(wiener_deconvolved_data)\n","    # adaptive histogram equalization\n","    adapeq_data = exposure.equalize_adapthist(histeq_data, clip_limit=0.02, kernel_size=None)\n","    # adaptive histogram equalization again\n","    adapeq_data = exposure.equalize_adapthist(adapeq_data, clip_limit=0.99, kernel_size=None)\n","    # Gaussian filtering 4 times\n","    filtered_image_data = adapeq_data.copy()\n","    for j in range(4):\n","      filtered_image_data = gaussian(filtered_image_data, sigma=1)\n","      filtered_image_data = restoration.denoise_tv_chambolle(filtered_image_data, weight=0.1)\n","    # morphological closing operation\n","    selem = disk(5)\n","    closed_image_data = closing(filtered_image_data, selem)\n","    return closed_image_data"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OPP9UHq8cbC4"},"source":["**Importing Datasets and Directory Set Up**\n","\n","imports raw dataset into notebook.\n","\n","Imports images to a dicontary of format dataset[folder]->Image\n","\n","Images are imported and the preprocessing is applied before converting to numpy array, and saving to the dictionary dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3554271,"status":"ok","timestamp":1683853547753,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"},"user_tz":300},"id":"VwWO5y5q0DKg","outputId":"226bbf12-fac2-4aa7-c30f-621bee020ec9"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\zacli\\AppData\\Local\\Temp\\ipykernel_14536\\466942546.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  data = np.array(data)\n"]}],"source":["dataset = {}\n","\n","# Loop through all folders in the directory and import images\n","for folder in sorted(os.listdir(path)):\n","    folder_path = os.path.join(path, folder)\n","    data = []\n","    # Find all image files in the folder\n","    image_paths = glob.glob(os.path.join(folder_path, '*'))\n","\n","    # Sort the image paths\n","    image_paths = sorted(image_paths)\n","\n","    for image_path in image_paths:\n","        # Check the file extension\n","        _, ext = os.path.splitext(image_path)\n","        # Convert .mrc images to PNG\n","        if ext.lower() == '.mrc':\n","            # Define the output path for the converted PNG image\n","            png_path = os.path.splitext(image_path)[0] + '.png'\n","\n","            # Check if the PNG image already exists\n","            if not os.path.exists(png_path):\n","                # Convert the .mrc image to PNG\n","                image = Image.open(image_path)\n","                image.save(png_path, 'PNG')\n","\n","            # Load the PNG image\n","            image = cv2.imread(png_path)\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        else:\n","            # Import image and convert to RGB values\n","            image = cv2.imread(image_path)\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        if image is not None:\n","            preprocessed_image = preprocess_image(image)\n","            data.append(preprocessed_image)\n","\n","    # Convert data to numpy arrays\n","    data = np.array(data)\n","\n","    # Add the data to the dataset dictionary\n","    dataset[folder] = data"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"A0YcuB5zcyRh"},"source":["**Setup output directories**\n","\n","setup subdirectory in output directory based on folder labels\n","\n","output directory will now match the shape and style of the input directory"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2761,"status":"ok","timestamp":1683853550499,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"},"user_tz":300},"id":"C-TWvJ9y7Z6q"},"outputs":[],"source":["# Remove all files and subdirectories inside the directory\n","if os.path.exists(path_output):\n","    shutil.rmtree(path_output)\n","# Create the directory and label subdirectories\n","# store the output of the preprocessing into seperate folders\n","os.makedirs(path_output)\n","# get all labels for directory creation\n","labels = dataset.keys()\n","# create and label subdirectories\n","for label in labels:\n","    # create path\n","    label_dir = os.path.join(path_output, label)\n","    # make dir\n","    if not os.path.exists(label_dir):\n","      os.makedirs(label_dir)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YYgkY2mfdASP"},"source":["**Save processed data**\n","\n","Saves the processed data as .npy files in the output directories"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":25649,"status":"ok","timestamp":1683853576146,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"},"user_tz":300},"id":"2DhqCIdZ7Fh9"},"outputs":[],"source":["for folder in dataset.keys():\n","    folder_path = os.path.join(path_output, folder)\n","    # Loop through all images in the folder\n","    for i, image in enumerate(dataset[folder]):\n","        # Construct the file name\n","        file_name = f\"{folder}_{i+1:03}.npy\"\n","        file_path = os.path.join(folder_path, file_name)\n","        np.save(file_path, image)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOYry0aYyuPg4g+8ZXe/5If","gpuType":"T4","machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}
