{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPeMd3cU4ESvwXQ/PlGPp37"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**DeepCryoPicker - PreProcessing**"],"metadata":{"id":"UUO9kFFxYxXL"}},{"cell_type":"markdown","source":["**Imports**"],"metadata":{"id":"f5_bFChIdYhK"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import os\n","import cv2\n","import shutil\n","from PIL import Image\n","from skimage import exposure, restoration, color\n","from skimage.morphology import disk, closing\n","from skimage.filters import gaussian\n","from scipy.signal import convolve2d\n"],"metadata":{"id":"s202UZaDdXh7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Importing Datasets and Directory Set Up**\n","\n","imports raw dataset into notebook\n","\n","setsup output directories\n","\n","This was tested on google drive\n","if using google drive run mount drive and connect\n","\n","Copy path to raw dataset\n","\n","Set the path for output directory"],"metadata":{"id":"CDsXWZ1hpswU"}},{"cell_type":"code","source":["# mount drive\n","# if you are not running this through google drive, than skip\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"d3Paujz9pYFl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Set the required directory paths**\n","\n","path - directory containing the raw datasets\n","\n","path_output - where this notebook will save the proccessed images"],"metadata":{"id":"cUkf3j4vql4c"}},{"cell_type":"code","source":["#drive path to directory containg datasets\n","path = \"/content/drive/MyDrive/DeepCryoPicker/Data Sets\"\n","\n","#drive path to output directory for preprocessed_data\n","path_output = \"/content/drive/MyDrive/DeepCryoPicker/preprocessed_data\""],"metadata":{"id":"f8u87qdWqLRE","executionInfo":{"status":"ok","timestamp":1683504149366,"user_tz":300,"elapsed":6,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["**Import raw data into a dict**\n","\n","dict is saved as dataset[folder_name]->data"],"metadata":{"id":"F_zVABk9q6qY"}},{"cell_type":"code","source":["#empty dictonary to store image data\n","dataset = {}\n","# Loop through all folders in the directory and import images\n","# images will be stored as dataset['folder'][data]\n","for folder in os.listdir(path):\n","  folder_path = os.path.join(path, folder)\n","  data = []\n","  for image_path in os.listdir(folder_path):\n","    # imprt data\n","    image = cv2.imread(os.path.join(folder_path, image_path))\n","    # convert data to RGB values\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    if image is not None:\n","            data.append(image)\n","  # Convert data to numpy arrays\n","  data = np.array(data)\n","  # Add the data to the dataset dictionary\n","  dataset[folder] = data\n","# remove 'Test' folder from our dataset\n","# test was used for various testing files (removing it breaks the dictonary structure for some reason)\n","del dataset['Test']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awFdjFi3p79t","executionInfo":{"status":"ok","timestamp":1681859057981,"user_tz":300,"elapsed":80414,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"}},"outputId":"73b89755-b64f-48ca-bdcd-5d10175b58e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3d2985ef84cb>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  data = np.array(data)\n"]}]},{"cell_type":"markdown","source":["**Set up output directory**\n","\n","This is expecting a path to an empty directory.\n","\n","will create subdirectories for each folder_name found in dataset{}"],"metadata":{"id":"ekdDKNXQrJF0"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9NAhTtfYtDx","executionInfo":{"status":"ok","timestamp":1681859067737,"user_tz":300,"elapsed":1220,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"}},"outputId":"27ab2972-7035-4344-e322-446fa6e5c25b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Remove all files and subdirectories inside the directory\n","if os.path.exists(path_output):\n","    shutil.rmtree(path_output)\n","# Create the directory and label subdirectories\n","# store the output of the preprocessing into seperate folders\n","os.makedirs(path_output)\n","# get all labels for directory creation\n","labels = dataset.keys()\n","# create and label subdirectories\n","for label in labels:\n","    # create path\n","    label_dir = os.path.join(path_output, label)\n","    # make dir\n","    if not os.path.exists(label_dir):\n","      os.makedirs(label_dir)"]},{"cell_type":"markdown","source":["**PreProcessing step**\n","\n","Preprocessing is a critical step in image analysis that involves preparing the image data for further processing. This typically involves a series of operations to correct for various artifacts and distortions in the image data, and to extract relevant features from the images. \n","\n","\n","The goal of preprocessing is to improve the quality and relevance of the image data, and to prepare it for further processing and analysis. Proper preprocessing can have a significant impact on the accuracy and reliability of downstream analysis, so it is important to carefully choose and optimize preprocessing steps for each particular application. \n","\n","For this model the following are the preprocessing steps taken:\n","\n","\n",">   **Image Normalization**\n",">> Indented scales the pixel values of an image to a consistent range or distribution. This helps to remove biases or inconsistencies in the data and improve its suitability for subsequent processing and analysis.\n","\n","> **Image Adjustment**\n",">> involves modifying the pixel values of an image to improve its quality or contrast. Here we use stretch and gamma adjustment\n","\n","> **Image Restoration**\n",">>  aims to improve the quality of an image by removing noise, blurring, or other distortions.The practices used here are:\n",">>>**Histogram equalization**\n",">>>>enhances the contrast of an image by redistributing the pixel intensities. This involves adjusting the image's histogram so that it is more evenly distributed across the available range of pixel values.\n","\n",">>>**Weiner Deconvolution**\n",">>>> technique used to restore images that have been degraded by blurring or noise. It involves applying a deconvolution filter to the image, which estimates the original, unblurred image by removing the effects of the blurring process. \n","\n",">**Adaptive Histogram Equalization**\n",">>hance the contrast of an image, particularly in areas with low contrast or uneven illumination. Unlike traditional histogram equalization, which operates on the entire image, AHE applies the equalization on local patches of the image. This means that the contrast enhancement is localized to specific regions of the image, preserving the contrast in other regions. \n","\n",">**Gaussian Filtering**\n",">>smoothing an image by applying a Gaussian filter to the image data. The Gaussian filter is a low-pass filter that effectively removes high-frequency noise from the image, while preserving the overall spatial structure of the image.\n","\n",">**Morphological Operations (closing)**\n",">> technique that involves modifying the shape or structure of objects in an image. These operations can be used to remove noise or to enhance specific features in an image, such as edges or boundaries. \n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"rAfJweVTpnRF"}},{"cell_type":"code","source":["# create new dictionary to hold the preprocessed data\n","processed_dataset = {}\n","print(\"Staring data processing:\\n\")\n","# Loop over each image in the dataset\n","for label in dataset.keys():\n","  data_pre = []\n","  print(\"Current Dataset:\"+ str(label))\n","  i=0\n","  # Loop over each image in the label's 'data' list\n","  for data in dataset[label]:\n","    print(\"image number: \" + str(i))\n","    i=i+1\n","    print(\"start...\")\n","    # preprocessing\n","    # image normalization: pixel values are in the range [0,1]\n","    normalized_data = data/np.max(data)\n","    # conver image to greyscale\n","    gray_image_data = color.rgb2gray(normalized_data)\n","    # # image adjustment (stretch and adjust)\n","    # # stretch the contrast of the image to represent the 5th and 95th percentiles of the pixel intensity distribution\n","    p1, p2 = np.percentile(gray_image_data, (5,95))\n","    stretched_data = exposure.rescale_intensity(gray_image_data, in_range=(p1, p2))\n","    # Adjust the contrast and brightness of the image\n","    adjusted_data = exposure.adjust_gamma(stretched_data, gamma=0.5)\n","    # image restoration (histogram equalization and weiner deconvolution)\n","    # histogram equalization\n","    histeq_data = exposure.equalize_hist(adjusted_data)\n","    # weiner deconvolution\n","    # the psf used is a general approximation, a better estimate can be created for our data set (possible improvment, though probably small)\n","    psf = np.ones((3, 3)) / 9\n","    blurred_data = convolve2d(histeq_data, psf, mode='same', boundary='symm')\n","    wiener_deconvolved_data = restoration.wiener(blurred_data, psf, balance=0.1)\n","    # histogram equlization\n","    histeq_data = exposure.equalize_hist(wiener_deconvolved_data)\n","    # adaptive histogram equalization\n","    adapeq_data = exposure.equalize_adapthist(histeq_data, clip_limit=0.02, kernel_size=None)\n","    # adaptive histogram equalization again\n","    adapeq_data = exposure.equalize_adapthist(adapeq_data, clip_limit=0.99, kernel_size=None)\n","    # Gaussian filtering 4 times\n","    filtered_image_data = adapeq_data.copy()\n","    for j in range(4):\n","      filtered_image_data = gaussian(filtered_image_data, sigma=1)\n","      filtered_image_data = restoration.denoise_tv_chambolle(filtered_image_data, weight=0.1)\n","    # morphological closing operation\n","    selem = disk(5)\n","    closed_image_data = closing(filtered_image_data, selem)\n","    # save the preprocessed image to directory\n","    data_pre.append(closed_image_data)\n","    print(\"completed\")\n","  # Convert data and labels to numpy arrays\n","  data_pre = np.array(data_pre)\n","  # Add the data and labels to the dataset dictionary\n","  processed_dataset[label] = data_pre\n","  print(\"Finished processing for Dataset: \" + str(label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0lVVgARmuD1","outputId":"0d3ff614-7bc9-49d6-e44b-43fad1f195c5","executionInfo":{"status":"ok","timestamp":1681863427007,"user_tz":300,"elapsed":4352547,"user":{"displayName":"zac lipperd","userId":"11300311766007752753"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-631360502570>:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  data_pre = np.array(data_pre)\n"]}]},{"cell_type":"markdown","source":["**Save processed Images too output directory**"],"metadata":{"id":"rvFDPc_hBqaw"}},{"cell_type":"code","source":["for folder in processed_dataset.keys():\n","  folder_path = folder_path = os.path.join(path_output, folder)\n","  # Loop through all images in the folder\n","  for i, image in enumerate(processed_dataset[folder]):\n","    # Construct the file name\n","    file_name = f\"{folder}_{i+1:03}.png\"\n","    file_path = os.path.join(folder_path, file_name)\n","    image = image\n","    cv2.imwrite(file_path,image)"],"metadata":{"id":"hbld7ZoTJYC7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Information Gathering**\n","\n","Gather data regarding pre and post processed data:\n","MSE, PSNR, SNR, histograms"],"metadata":{"id":"Z0JlWGAd5HLN"}},{"cell_type":"code","source":["#save example images(first 5 of each set) for report (normalized values to integer range)\n","path_save = \"/content/drive/MyDrive/DeepCryoPicker/Report/Processed Images\"\n","for folder in processed_dataset.keys():\n","  # Create a new directory with the same name as the folder\n","  folder_path = os.path.join(path_save, folder)\n","  os.makedirs(folder_path, exist_ok=True)\n","  # Loop through all images in the folder\n","  for i, image in enumerate(processed_dataset[folder]):\n","    # Construct the file name\n","    if i < 5:\n","      file_name = f\"{folder}_{i+1:03}.png\"\n","      file_path = os.path.join(folder_path, file_name)\n","      image = image*255\n","      cv2.imwrite(file_path,image)"],"metadata":{"id":"wUFMHKdV9HgS"},"execution_count":null,"outputs":[]}]}